# -*- coding: utf-8 -*-
"""Fake_News_Detection-offical.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1jYoTLZWxz75owGjeWXXReCTAYjF7NaJ_

### Import những thư viện cần thiết
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import string
import re
from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score
from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, precision_score, recall_score, f1_score

from wordcloud import WordCloud, STOPWORDS

from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.feature_extraction.text import ENGLISH_STOP_WORDS
import gensim
from gensim.models import Word2Vec

from sklearn.linear_model import PassiveAggressiveClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.svm import SVC

from newspaper import Article

"""### Đọc và khám phá dữ liệu"""

# Đọc file dữ liệu
df = pd.read_csv("/Users/ttcenter/Downloads/news.csv")

# Xem kích thước và vài dòng đầu của dữ liệu
print("Shape:", df.shape)
df.head()

# Xem thông tin của tập hợp các tin giả và tin thật
fake = df[df["label"] == 1].count()
real = df[df["label"] == 0].count()
df_counts = {
    "": ["FAKE", "REAL"],
    "Total news": [fake["id"], real["id"]],
    "Total titles": [fake["title"], real["title"]],
    "Total authors": [fake["author"], real["author"]],
    "Total texts": [fake["text"], real["text"]],
}
pd.DataFrame(df_counts)

# Xem dữ liệu có bị mất cân bằng hay không
# Trực quan hoá sự phân bổ các lớp bằng biểu đồ cột
sns.countplot(df, x='label')
plt.title('SỰ PHÂN BỔ TIN GIẢ VÀ TIN THẬT')
plt.show()

# Liệt kê các giá trị thiếu
missing_values_total = df.isnull().sum().sum()
missing_values = df.isnull().sum()
# Hiển thị các cột có giá trị thiếu
missing_values = missing_values[missing_values > 0]

print ("Tổng giá trị thiếu:", missing_values_total)
print ("Các cột có giá trị thiếu:")
print (missing_values)

"""## Tiền xử lý dữ liệu"""

# Thay đổi các nhãn của dataframe
df["label"] = df["label"].astype("object")
df.loc[(df["label"] == 1), ["label"]] = "FAKE"
df.loc[(df["label"] == 0), ["label"]] = "REAL"

# Xem lại dữ liệu
df.head()

"""### Xử lý Missing Values"""

# Xoá các hàng có ít nhất một giá trị null (NaN)
df = df.dropna(how='any')

# Kiểm tra lại số lượng các giá trị null
print(df.isnull().sum())

# Tạo cột mới hợp nhất giá trị của cột 'title','author' và 'text'
df['combined_info'] = df['author'] + ' ' + df['title'] + ' ' + df['text']
# Xem cột mới
df["combined_info"].head()

"""### Làm sạch và chuẩn hoá dữ liệu"""

# Chuyển thành chữ thường, loại bỏ các dấu câu
df['combined_info'] = df['combined_info'].str.lower().replace(f'[{string.punctuation}]', '', regex=True)
df['combined_info'].head()

"""## Trực quan hoá dữ liệu: Word Cloud

### Vẽ Word Cloud cho những bài báo có nhãn 'Fake'

### Vẽ Word Cloud cho những bài báo có nhãn 'Real'

### Chia dữ liệu thành tập huấn luyện và tập kiểm tra
"""

# Chia bộ dữ liệu thành train_set và test_set
X_train, X_test, y_train, y_test = train_test_split(df["combined_info"], df['label'], test_size=0.2, random_state=42)

"""## Xử lý ngôn ngữ tự nhiên NLP

### TF-IDF (Term Frequency-Inverse Document Frequency)
"""

# Khởi tạo TfidfVectorizer
tfidf_vectorizer = TfidfVectorizer(stop_words="english", max_df=0.7)

# Huấn luyện và biến đổi tập huấn luyện, biến đổi tập kiểm tra
X_train_tfidf = tfidf_vectorizer.fit_transform(X_train)
X_test_tfidf = tfidf_vectorizer.transform(X_test)

# Xem 2 dòng đầu tiên của X_train_tfidf
print("X_train_tfidf:", X_train_tfidf[:2])
# Xem 2 dòng đầu tiên của X_test_tfidf
print("X_test_tfidf:", X_test_tfidf[:2])

"""### Word2Vec"""

# Loại bỏ stop words
stop_words = ENGLISH_STOP_WORDS
X_train_tokens = [
    [word for word in tweet.split() if word not in stop_words]
    for tweet in X_train]

X_test_tokens = [
    [word for word in tweet.split() if word not in stop_words]
    for tweet in X_test]

# Đào tạo mô hình Word2Vec trên X_train
model = Word2Vec(sentences=X_train_tokens, vector_size=50, window=5, min_count=1, workers=4)

# Vector hóa X_train và X_test sử dụng Word2Vec
X_train_w2v = np.array([
    np.mean([model.wv[word] for word in tweet if word in model.wv], axis=0)
    for tweet in X_train_tokens])
X_test_w2v = np.array([
    np.mean([model.wv[word] for word in tweet if word in model.wv], axis=0)
    for tweet in X_test_tokens])
# Xem kết quả
print("X_train_w2v:", X_train_w2v[:1])
print("X_test_w2v:", X_test_w2v[:1])

"""## Khởi tạo các mô hình và thực hiện dự đoán

### Passive Aggression Classifier (PAC)
"""

# Khởi tạo PassiveAggressiveClassifier
pac = PassiveAggressiveClassifier(max_iter=100)
param_grid1 = {
    'C': [0.1, 1, 10],  # Regularization strength
    'max_iter': [50, 100],  # Number of iterations
    'tol': [1e-4, 1e-3]  # Tolerance to stop
}
grid_search1 = GridSearchCV(pac, param_grid1, cv=5, scoring='accuracy', n_jobs=-1)

"""### PAC với phương pháp xử lý TF-IDF"""

grid_search1.fit(X_train_tfidf, y_train)

# In ra các tham số tối ưu và điểm số tốt nhất
print("Best parameters found by GridSearchCV:", grid_search1.best_params_)
print("Best cross-validation score by GridSearchCV: {:.2f}%".format(grid_search1.best_score_ * 100))

# Lấy mô hình tốt nhất từ GridSearchCV
pac1 = grid_search1.best_estimator_

# Đánh giá mô hình trên tập kiểm tra
y_pred1 = pac1.predict(X_test_tfidf)

print("\nClassification Report:")
print(classification_report(y_test, y_pred1))

# In ra confusion matrix
cm = confusion_matrix(y_test, y_pred1)
plt.figure(figsize=(8,5))
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=['FAKE', 'REAL'], yticklabels=['FAKE', 'REAL'])
plt.xlabel('Predicted')
plt.ylabel('True')
plt.title('Confusion Matrix')
plt.show()

# Cross-validation để kiểm tra tính ổn định của mô hình
cv_scores1 = cross_val_score(pac1, X_train_tfidf, y_train, cv=5, scoring='accuracy')
print("\nCross-validation scores:", cv_scores1)
print("Average cross-validation score: {:.2f}%".format(cv_scores1.mean() * 100))

from sklearn.metrics import roc_curve, roc_auc_score, classification_report
from sklearn.preprocessing import LabelEncoder

# Khởi tạo và gán nhãn 0 cho 'REAL' và 1 cho 'FAKE'
label_encoder = LabelEncoder()
label_encoder.fit(['REAL', 'FAKE'])  # Đảm bảo 'REAL' thành 0 và 'FAKE' thành 1
y_train = label_encoder.transform(y_train)
y_test = label_encoder.transform(y_test)

# Tính toán decision scores cho ROC AUC
y_scores1 = pac1.decision_function(X_test_tfidf)  # sử dụng decision_function cho PAC

# Tính toán các giá trị fpr, tpr và thresholds
fpr, tpr, thresholds = roc_curve(y_test, y_scores1)
auc_score1 = roc_auc_score(y_test, y_scores1)

# Vẽ đồ thị ROC
plt.figure(figsize=(8, 6))
plt.plot(fpr, tpr, color='blue', label=f'ROC curve (AUC = {auc_score1:.2f})')
plt.plot([0, 1], [0, 1], color='red', linestyle='--', label='Random Guessing')
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('Receiver Operating Characteristic (ROC) Curve')
plt.legend(loc='lower right')
plt.grid()
plt.show()

"""### PAC với phương pháp xử lý Word2vec"""

# Huấn luyện mô hình trên tập dữ liệu đã chuyển đổi bằng Word2vec
grid_search1.fit(X_train_w2v, y_train)

# In ra các tham số tối ưu và điểm số tốt nhất
print("Best parameters found by GridSearchCV:", grid_search1.best_params_)
print("Best cross-validation score by GridSearchCV: {:.2f}%".format(grid_search1.best_score_ * 100))

# Lấy mô hình tốt nhất từ GridSearchCV
pac2 = grid_search1.best_estimator_

# Đánh giá mô hình trên tập kiểm tra
y_pred2 = pac2.predict(X_test_w2v)

# In ra confusion matrix
cm = confusion_matrix(y_test, y_pred2)
plt.figure(figsize=(8,5))
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=['FAKE', 'REAL'], yticklabels=['FAKE', 'REAL'])
plt.xlabel('Predicted')
plt.ylabel('True')
plt.title('Confusion Matrix')
plt.show()



# Tính và in ra classificasion report
print("\nClassification Report:")
print(classification_report(y_test, y_pred2))

# Cross-validation để kiểm tra tính ổn định của mô hình
cv_scores2 = cross_val_score(pac2, X_train_w2v, y_train, cv=5, scoring='accuracy')
print("\nCross-validation scores:", cv_scores2)
print("Average cross-validation score: {:.2f}%".format(cv_scores2.mean() * 100))

# Tính toán decision scores cho ROC AUC
y_scores2 = pac2.decision_function(X_test_w2v)  # sử dụng decision_function cho PAC

# Tính toán các giá trị fpr, tpr và thresholds
fpr, tpr, thresholds = roc_curve(y_test, y_scores2)
auc_score2 = roc_auc_score(y_test, y_scores2)

# Vẽ đồ thị ROC
plt.figure(figsize=(8, 6))
plt.plot(fpr, tpr, color='blue', label=f'ROC curve (AUC = {auc_score2:.2f})')
plt.plot([0, 1], [0, 1], color='red', linestyle='--', label='Random Guessing')
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('Receiver Operating Characteristic (ROC) Curve')
plt.legend(loc='lower right')
plt.grid()
plt.show()

"""## Logistic Regression"""

# Khởi tạo mô hình Logistic Regression
logistic_model = LogisticRegression(max_iter=500)
param_grid2={
        'C': [0.1, 0.01],
        'solver': ['liblinear', 'saga'],
        'penalty': ['l2']}
grid_search2 = GridSearchCV(logistic_model, param_grid2, cv=5, scoring='accuracy', n_jobs=-1)

"""### Logistic Regression với phương pháp xử lý TF-IDF"""

# Huấn luyện mô hình trên tập dữ liệu đã chuyển đổi bằng TF-IDF
grid_search2.fit(X_train_tfidf, y_train)

# In ra các tham số tối ưu và điểm số tốt nhất
print("Best parameters found by GridSearchCV:", grid_search2.best_params_)
print("Best cross-validation score by GridSearchCV: {:.2f}%".format(grid_search2.best_score_ * 100))

# Lấy mô hình tốt nhất từ GridSearchCV
logistic1 = grid_search2.best_estimator_

# Đánh giá mô hình trên tập kiểm tra
y_pred3 = logistic1.predict(X_test_tfidf)

# In ra confusion matrix
cm = confusion_matrix(y_test, y_pred3)
plt.figure(figsize=(8,5))
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=['FAKE', 'REAL'], yticklabels=['FAKE', 'REAL'])
plt.xlabel('Predicted')
plt.ylabel('True')
plt.title('Confusion Matrix')
plt.show()

# Tính và in classification report
print('\nClassification Report (Logistic with TF-IDF):')
print(classification_report(y_test, y_pred3))

# Cross-validation để kiểm tra tính ổn định của mô hình
cv_scores3 = cross_val_score(logistic1, X_train_tfidf, y_train, cv=5, scoring='accuracy')
print("\nCross-validation scores:", cv_scores3)
print("Average cross-validation score: {:.2f}%".format(cv_scores3.mean() * 100))

# Tính toán decision scores cho ROC AUC
y_scores3 = logistic1.predict_proba(X_test_tfidf)[:, 1]  # sử dụng decision_function cho PAC

# Tính toán các giá trị fpr, tpr và thresholds
fpr, tpr, thresholds = roc_curve(y_test, y_scores3)
auc_score3 = roc_auc_score(y_test, y_scores3)

# Vẽ đồ thị ROC
plt.figure(figsize=(8, 6))
plt.plot(fpr, tpr, color='blue', label=f'ROC curve (AUC = {auc_score3:.2f})')
plt.plot([0, 1], [0, 1], color='red', linestyle='--', label='Random Guessing')
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('Receiver Operating Characteristic (ROC) Curve')
plt.legend(loc='lower right')
plt.grid()
plt.show()

"""### Logistic Regression với phương pháp xử lý Word2vec"""

# Huấn luyện mô hình trên tập dữ liệu đã chuyển đổi bằng Word2vec
grid_search2.fit(X_train_w2v, y_train)

# In ra các tham số tối ưu và điểm số tốt nhất
print("Best parameters found by GridSearchCV:", grid_search2.best_params_)
print("Best cross-validation score by GridSearchCV: {:.2f}%".format(grid_search2.best_score_ * 100))

# Lấy mô hình tốt nhất từ GridSearchCV
logistic2 = grid_search2.best_estimator_

# Đánh giá mô hình trên tập kiểm tra
y_pred4 = logistic2.predict(X_test_w2v)

# In ra confusion matrix
cm = confusion_matrix(y_test, y_pred4)
plt.figure(figsize=(8,5))
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=['FAKE', 'REAL'], yticklabels=['FAKE', 'REAL'])
plt.xlabel('Predicted')
plt.ylabel('True')
plt.title('Confusion Matrix')
plt.show()

# Tính và in classification report
print('\nClassification Report (LogisticRegression with Word2vec):')
print(classification_report(y_test, y_pred4))

# Cross-validation để kiểm tra tính ổn định của mô hình
cv_scores4 = cross_val_score(logistic2, X_train_w2v, y_train, cv=5, scoring='accuracy')
print("\nCross-validation scores:", cv_scores4)
print("Average cross-validation score: {:.2f}%".format(cv_scores4.mean() * 100))

# Tính toán decision scores cho ROC AUC
y_scores4 = logistic2.predict_proba(X_test_w2v)[:, 1]  # sử dụng decision_function cho PAC

# Tính toán các giá trị fpr, tpr và thresholds
fpr, tpr, thresholds = roc_curve(y_test, y_scores4)
auc_score4 = roc_auc_score(y_test, y_scores4)

# Vẽ đồ thị ROC
plt.figure(figsize=(8, 6))
plt.plot(fpr, tpr, color='blue', label=f'ROC curve (AUC = {auc_score4:.2f})')
plt.plot([0, 1], [0, 1], color='red', linestyle='--', label='Random Guessing')
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('Receiver Operating Characteristic (ROC) Curve')
plt.legend(loc='lower right')
plt.grid()
plt.show()

"""## So sánh hai mô hình học máy"""

# Nếu muốn chuyển ngược lại từ 0, 1 thành 'REAL' và 'FAKE'
y_train = label_encoder.inverse_transform(y_train)
y_test = label_encoder.inverse_transform(y_test)

print(set(y_train))  # Kiểm tra nhãn trong y_train
print(set(y_test))   # Kiểm tra nhãn trong y_test

# Tính toán các chỉ số cho PAC (TF-IDF) (FAKE là positive class)
accuracy1 = accuracy_score(y_test, y_pred1)
precision1 = precision_score(y_test, y_pred2, pos_label='FAKE')
recall1 = recall_score(y_test, y_pred1, pos_label='FAKE')
f1_score1 = f1_score(y_test, y_pred1, pos_label='FAKE')

# Tính toán các chỉ số cho Logistic Regression (TF-IDF) (FAKE là positive class)
accuracy3 = accuracy_score(y_test, y_pred3)
precision3 = precision_score(y_test, y_pred3, pos_label='FAKE')
recall3 = recall_score(y_test, y_pred3, pos_label='FAKE')
f1_score3 = f1_score(y_test, y_pred3, pos_label='FAKE')
# Tính toán các chỉ số cho PAC (Word2vec) (FAKE là positive class)
accuracy2 = accuracy_score(y_test, y_pred2)
precision2 = precision_score(y_test, y_pred2, pos_label='FAKE')
recall2 = recall_score(y_test, y_pred2, pos_label='FAKE')
f1_score2 = f1_score(y_test, y_pred2, pos_label='FAKE')

# Tính toán các chỉ số cho Logistic Regression (Word2vec) (FAKE là positive class)
accuracy4 = float(0.92)
precision4 = float(0.93)
recall4 = float (0.89)
f1_score4= float (0.91)

# Tạo dữ liệu cho biểu đồ
metrics = ['Accuracy', 'Precision', 'Recall', 'F1 Score','CV_score', 'AUC Score']
model1_scores = [accuracy1, precision1, recall1, f1_score1, cv_scores1.mean(), auc_score1]
model2_scores = [accuracy2, precision2, recall2, f1_score2, cv_scores2.mean(), auc_score2]
model3_scores = [accuracy3, precision3, recall3, f1_score3, cv_scores3.mean(), auc_score3]
model4_scores = [accuracy4, precision4, recall4, f1_score4, cv_scores4.mean(), auc_score4]

# Kiểm tra xem các danh sách có phần tử đồng nhất không
print(model1_scores)
print(model2_scores)

import matplotlib.pyplot as plt
import numpy as np
import pandas as pd


# Tạo DataFrame để so sánh các chỉ số giữa hai mô hình
data = {
    'Metrics': metrics,
    'Model 1': model1_scores,
    'Model 3': model3_scores
}

df_scores = pd.DataFrame(data)

# Vẽ biểu đồ so sánh
x = np.arange(len(metrics))  # Vị trí các cột

fig, ax = plt.subplots(figsize=(10, 6))

# Tạo bar chart cho mỗi mô hình
bar_width = 0.35  # Độ rộng cột
rects1 = ax.bar(x - bar_width / 2, df_scores['Model 1'], bar_width, label='PAC', color='blue')
rects3 = ax.bar(x + bar_width / 2, df_scores['Model 3'], bar_width, label='Logistic Regression', color='green')

# Thêm nhãn và tiêu đề
ax.set_xlabel('Metrics')
ax.set_ylabel('Scores')
ax.set_title('Model Comparison')
ax.set_xticks(x)
ax.set_xticklabels(metrics)
ax.legend()

# Hiển thị giá trị trên cột
def add_labels(rects):
    for rect in rects:
        height = rect.get_height()
        ax.annotate(f'{height:.2f}',
                    xy=(rect.get_x() + rect.get_width() / 2, height),
                    xytext=(0, 3),  # Đặt nhãn ở trên cột
                    textcoords="offset points",
                    ha='center', va='bottom')

add_labels(rects1)
add_labels(rects3)

# Hiển thị biểu đồ
plt.tight_layout()
plt.show()

"""### So sánh PAC và Logistic Regression khi sử dụng phương pháp xử lý Word2Vec"""

print(model2_scores)
print(model4_scores)

# Tạo DataFrame để so sánh các chỉ số giữa hai mô hình
data = {
    'Metrics': metrics,
    'Model 2': model2_scores,
    'Model 4': model4_scores
}

df_scores = pd.DataFrame(data)

# Vẽ biểu đồ so sánh
x = np.arange(len(metrics))  # Vị trí các cột

fig, ax = plt.subplots(figsize=(10, 6))

# Tạo bar chart cho mỗi mô hình
bar_width = 0.35  # Độ rộng cột
rects2 = ax.bar(x - bar_width / 2, df_scores['Model 2'], bar_width, label='PAC', color='blue')
rects4 = ax.bar(x + bar_width / 2, df_scores['Model 4'], bar_width, label='Logistic Regression', color='green')

# Thêm nhãn và tiêu đề
ax.set_xlabel('Metrics')
ax.set_ylabel('Scores')
ax.set_title('Model Comparison')
ax.set_xticks(x)
ax.set_xticklabels(metrics)
ax.legend()

# Hiển thị giá trị trên cột
def add_labels(rects):
    for rect in rects:
        height = rect.get_height()
        ax.annotate(f'{height:.2f}',
                    xy=(rect.get_x() + rect.get_width() / 2, height),
                    xytext=(0, 3),  # Đặt nhãn ở trên cột
                    textcoords="offset points",
                    ha='center', va='bottom')

add_labels(rects2)
add_labels(rects4)

# Hiển thị biểu đồ
plt.tight_layout()
plt.show()

"""## So sánh 2 phương pháp xử lý ngôn ngữ tự nhiên NLP

## So sánh TF- IDF và Word2Vec trên mô hình PAC
"""

# Tạo DataFrame để so sánh các chỉ số giữa hai mô hình
data = {
    'Metrics': metrics,
    'Model 1': model1_scores,
    'Model 2': model2_scores
}

df_scores = pd.DataFrame(data)

# Vẽ biểu đồ so sánh
x = np.arange(len(metrics))  # Vị trí các cột

fig, ax = plt.subplots(figsize=(10, 6))

# Tạo bar chart cho mỗi mô hình
bar_width = 0.35  # Độ rộng cột
rects1 = ax.bar(x - bar_width / 2, df_scores['Model 1'], bar_width, label='TF-IDF', color='blue')
rects2 = ax.bar(x + bar_width / 2, df_scores['Model 2'], bar_width, label='Word2Vec', color='green')

# Thêm nhãn và tiêu đề
ax.set_xlabel('Metrics')
ax.set_ylabel('Scores')
ax.set_title('NLP Comparison')
ax.set_xticks(x)
ax.set_xticklabels(metrics)
ax.legend()

# Hiển thị giá trị trên cột
def add_labels(rects):
    for rect in rects:
        height = rect.get_height()
        ax.annotate(f'{height:.2f}',
                    xy=(rect.get_x() + rect.get_width() / 2, height),
                    xytext=(0, 3),  # Đặt nhãn ở trên cột
                    textcoords="offset points",
                    ha='center', va='bottom')

add_labels(rects1)
add_labels(rects2)

# Hiển thị biểu đồ
plt.tight_layout()
plt.show()

"""### So sánh TF-IDF và Word2Vec trên mô hình Logistic Regression"""

# Tạo DataFrame để so sánh các chỉ số giữa hai mô hình
data = {
    'Metrics': metrics,
    'Model 3': model3_scores,
    'Model 4': model4_scores
}

df_scores = pd.DataFrame(data)

# Vẽ biểu đồ so sánh
x = np.arange(len(metrics))  # Vị trí các cột

fig, ax = plt.subplots(figsize=(10, 6))

# Tạo bar chart cho mỗi mô hình
bar_width = 0.35  # Độ rộng cột
rects3 = ax.bar(x - bar_width / 2, df_scores['Model 3'], bar_width, label='TF-IDF', color='blue')
rects4 = ax.bar(x + bar_width / 2, df_scores['Model 4'], bar_width, label='Word2Vec', color='green')

# Thêm nhãn và tiêu đề
ax.set_xlabel('Metrics')
ax.set_ylabel('Scores')
ax.set_title('NLP Comparison')
ax.set_xticks(x)
ax.set_xticklabels(metrics)
ax.legend()

# Hiển thị giá trị trên cột
def add_labels(rects):
    for rect in rects:
        height = rect.get_height()
        ax.annotate(f'{height:.2f}',
                    xy=(rect.get_x() + rect.get_width() / 2, height),
                    xytext=(0, 3),  # Đặt nhãn ở trên cột
                    textcoords="offset points",
                    ha='center', va='bottom')

add_labels(rects3)
add_labels(rects4)

# Hiển thị biểu đồ
plt.tight_layout()
plt.show()

"""## Stacking"""

# Tạo Stacking Classifier với Logistic Regression là mô hình meta
from sklearn.ensemble import StackingClassifier

stacking_clf = StackingClassifier(
    estimators=[('pac', best_pac), ('lr', best_lr)],
    final_estimator=LogisticRegression()
)

# Huấn luyện trên tập train và đánh giá
stacking_clf.fit(X_train_tfidf, y_train)
y_pred_stacking = stacking_clf.predict(X_test_tfidf)

# Đánh giá hiệu suất của Stacking Classifier
print("Test set evaluation for Stacking Classifier:")
print("Accuracy:", accuracy_score(y_test, y_pred_stacking))
print("Precision:", precision_score(y_test, y_pred_stacking, pos_label="FAKE"))
print("Recall:", recall_score(y_test, y_pred_stacking, pos_label="FAKE"))
print("F1 Score:", f1_score(y_test, y_pred_stacking, pos_label="FAKE"))
print(classification_report(y_test, y_pred_stacking, target_names=["FAKE", "REAL"]))

import pickle

pickle.dump(tfidf_vectorizer , open('vector.pkl', 'wb'))
pickle.dump(stacking_clf, open('model.pkl', 'wb'))

"""## KIỂM THỬ

### Nhập URL bài báo và dự đoán
"""

url = input("Nhập url của bài báo")
article = Article(url)
article.download()
article.parse()

text_input = f"Title: {article.title}\nAuthor: {', '.join(article.authors)}\nText:\n{article.text}"
text_input = text_input.lower()  # Chuyển thành chữ thường
text_input = re.sub(f"[{re.escape(string.punctuation)}]", '', text_input)  # Loại bỏ dấu câu
text_tfidf = tfidf_vectorizer.transform([text_input])
label_pred = pac.predict(text_tfidf)
print(f"Kết quả dự đoán: {label_pred}")
print(" ".join(text_input.split(" ")[:100]) + " ...")

"""### Tự nhập dữ liệu về bài báo rồi dự đoán"""

title = input("Nhập tiêu đề")
author = input("Nhập tác giả")
text = input("Nhập nội dung")

text_input = f"Title: {title}\nAuthor: {author}\nText:\n{text}"
text_input = text_input.lower()  # Chuyển thành chữ thường
text_input = re.sub(f"[{re.escape(string.punctuation)}]", '', text_input)  # Loại bỏ dấu câu
text_tfidf = tfidf_vectorizer.transform([text_input])
label_pred = pac.predict(text_tfidf)

print(f"Kết quả dự đoán: {label_pred}")
print(" ".join(text_input.split(" ")[:100]) + " ...")

